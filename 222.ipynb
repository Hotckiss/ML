#%%
import pandas as pd
import numpy as np
data_folder = "../data/"

#%%
def read_data(csv_name):
    data = pd.read_csv(data_folder + csv_name)
    values, labels = data.drop(columns=['label']), data.label
    return values.values, labels.values

#%%
spam_values, spam_labels = read_data("spam.csv")
cancer_values, cancer_labels = read_data("cancer.csv")

#%%
# get k nearest for point exclude itself
def get_k_nearest(k, points, idx):
    current_point = points[idx]
    distances_to_current_point = []
    for point in points:
        distances_to_current_point.append(np.linalg.norm(current_point - point))
    sorted_neighbours = np.argsort(np.array(distances_to_current_point))
    return sorted_neighbours.tolist()[1:k + 1]

def knn_for_all_points(k, points):
    knn_matrix = []
    for idx in range(points.shape[0]):
        knn_matrix.append(get_k_nearest(k, points, idx))
    return knn_matrix

def classify_point(knn_matrix, labels, k, idx):
    classes, counts = np.unique(labels[knn_matrix[idx]][:k], return_counts=True)
    return classes[np.argmax(counts)]

def loo(knn_matrix, labels, k):
    n = len(labels)
    sum_labels = 0
    for idx in range(n):
        if classify_point(knn_matrix, labels, k, idx) != labels[idx]:
            sum_labels += 1.0
    return sum_labels / n
    
def loo_k(values, labels, k):
    knn_matrix = knn_for_all_points(k, values)
    loo_errors = []
    for idx in range(1, k + 1):
        loo_errors.append(loo(knn_matrix, labels, idx))
    return loo_errors 

#%%
def task1_result_cancer():
    print("cancer")
    cancer_loo = loo_k(cancer_values, cancer_labels, 10)
    for k, error in enumerate(cancer_loo):
        print("k = " + str(k + 1) + "; loo = " + str(error))
        
task1_result_cancer()

#%%
def task1_result_spam():
    print("spam")
    spam_loo = loo_k(spam_values, spam_labels, 10)
    for k, error in enumerate(spam_loo):
        print("k = " + str(k + 1) + "; loo = " + str(error))
        
task1_result_spam()

#%%
def scale(features):
    return (features - features.min(axis=0)) / (features.max(axis=0) - features.min(axis=0))

#%%
def task2_result_cancer():
    print("scaled_cancer")
    scaled_cancer_values = scale(cancer_values)
    cancer_loo = loo_k(scaled_cancer_values, cancer_labels, 10)
    for k, error in enumerate(cancer_loo):
        print("k = " + str(k + 1) + "; loo = " + str(error))
        
task2_result_cancer()

#%%
def task2_result_spam():
    print("scaled_spam")
    scaled_spam_values = scale(spam_values)
    spam_loo = loo_k(scaled_spam_values, spam_labels, 10)
    for k, error in enumerate(spam_loo):
        print("k = " + str(k + 1) + "; loo = " + str(error))
        
task2_result_spam()

#%%
blobs = pd.read_csv(data_folder + "blobs.csv").values

#%%
import random

def generate_initial_centers(values, count_of_centers):
    return random.sample(list(values), count_of_centers)

def k_means(values, k):
    centers = generate_initial_centers(values, k)
    n = len(values)
    
    while True:
        clusters_of_points = []
        
        for value in values:
            best_index = 0
            for center_index in range(k):
                if np.linalg.norm(value - centers[best_index]) > np.linalg.norm(value - centers[center_index]):
                    best_index = center_index
            clusters_of_points.append(best_index)
        
        cnt = np.zeros(n)
        old_centers = np.copy(centers)
        
        for i in range(k):
            centers[i] = np.array([0] * values.shape[1])
            
        for i in range(n):
            centers[clusters_of_points[i]] = np.array(centers[clusters_of_points[i]]) + values[i]
            cnt[clusters_of_points[i]] += 1
        
        for i in range(k):
            if cnt[i] != 0:
                centers[i] /= cnt[i]
            
        if np.allclose(old_centers, centers):
            break
        
    return np.array(clusters_of_points)

#%%
import matplotlib.pyplot as plt

def draw(values, clusters):
    c = ['black', 'red', 'green', 'blue', 'yellow', 'cyan']
    x = [row[0] for row in values]
    y = [row[1] for row in values]
    color = [c[i % 6] for i in clusters]
    
    plt.scatter(x, y, c=color)
    plt.xlabel('X')
    plt.ylabel('Y')
    plt.show()

#%%
def task3():
    for k in range(2, 6):
        clusters = k_means(blobs, k)
        draw(blobs, clusters)
        
task3()

#%%
def eps_neighbours(values, eps, point_idx):
    neighbors = []
    for i in range(len(values)):
        if point_idx != i and np.linalg.norm(values[point_idx] - values[i]) < eps:
            neighbors.append(i)
    return neighbors

def dbscan(values, m, eps):
    c = 0
    clusters = np.zeros(len(values), dtype=int)
    
    for i in range(len(values)):
        if clusters[i] != 0:
            continue
            
        neighbors = eps_neighbours(values, eps, i)

        if len(neighbors) < m:
            continue
        
        c += 1
        clusters[i] = c
        
        while True:
            nxt = []
            
            for j in neighbors:
                if clusters[j] != 0:
                    continue
                
                clusters[j] = c
                current = eps_neighbours(values, eps, j)
        
                if len(current) >= m:
                    nxt.extend(current)
 
            if len(nxt) == 0:
                break
                
            neighbors = np.copy(nxt)
        
    return np.array(clusters)

#%%
def task4():
    clusterizations = [dbscan(blobs, 40, 0.5), dbscan(blobs, 23, 0.36), dbscan(blobs, 23, 0.35), dbscan(blobs, 11, 0.24)]
    for partition in clusterizations:
        draw(blobs, partition)
    
task4()

#%%
from scipy.spatial import distance_matrix

#returns two clusters with minimal distance between them
# distance(c1, c2) = max(dist(point_from_c1, point_from_c2))
def find_closest_clusters(dist, clusters, max_dist):
    closest_clusters_indices = (0, 1)
    min_dist = max_dist
    n = len(clusters)
    for i in range(n):
        for j in range(i + 1, n):
            distance_between_clusters = max([dist[c1, c2] for c1 in clusters[i] for c2 in clusters[j]])
                
            if distance_between_clusters < min_dist:
                min_dist = distance_between_clusters
                closest_clusters_indices = (i, j)
                
    return closest_clusters_indices

def agglomerative_clustering(values, k):
    dist = distance_matrix(values, values)
    max_distance = dist.max()
    clusters = list([[i] for i in range(len(values))])
    
    while len(clusters) > k:
        c1, c2 = find_closest_clusters(dist, clusters, max_distance)
        clusters[c1] += clusters[c2]
        del clusters[c2]
        
    predict = np.zeros(len(values), dtype=int)
    for i in range(len(clusters)):
        for j in clusters[i]:
            predict[j] = i
            
    return predict

def task5():
    for k in range(2, 6):
        clusters = agglomerative_clustering(blobs, k)
        draw(blobs, clusters)
        
task5()
#%%
from sklearn import metrics

def purity(labels, clusters):
    contingency_matrix = metrics.cluster.contingency_matrix(labels, clusters)
    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)

#%%
def task6():
    for k in [2, 3, 5, 10]:
        clusters = k_means(cancer_values, k)
        print(purity(cancer_labels, clusters))
        
task6()

#%%
from sklearn import metrics

def roc_curves(values, labels):
    scores = [metrics.roc_auc_score(labels, values[:,i]) for i in range(values.shape[1])]
    best = np.argsort(scores)[-3:]
    
    return [metrics.roc_curve(labels, values[:,i], pos_label=1.0) for i in best]

def plot_curve(curve):
    plt.xlabel("FP")
    plt.ylabel("TP")
    plt.plot(curve[0], curve[1])
    plt.plot([0, 1], [0, 1])
    plt.show()

#%%
def task7_spam(): 
    curves = roc_curves(spam_values, spam_labels)
    for curve in curves:
        plot_curve(curve)

def task7_cancer():
    # pos_label='M' not working for me
    mapped_labels = list(map(lambda label: 1 if label == 'M' else 0, cancer_labels))
    curves = roc_curves(cancer_values, mapped_labels)
    for curve in curves:
        plot_curve(curve)

#%%
print("spam")
task7_spam()

#%%
print("cancer")
task7_cancer()

#%%
from sklearn.model_selection import train_test_split
from collections import defaultdict

def split_dataset(values, labels):
    values_train, values_test, labels_train, labels_test = train_test_split(values, labels, train_size=0.8)  
    return values_train, values_test, labels_train, labels_test

def proportions(labels):
    counters = defaultdict(float)
    for label in labels:
        counters[label] += 1
    return {k: v / len(labels) for k, v in counters.items()}

#%%
def task8_cancer():
    values_train, values_test, labels_train, labels_test = split_dataset(cancer_values, cancer_labels)
    print("cancer train proportions")
    print(proportions(labels_train))
    print("cancer test proportions")
    print(proportions(labels_test))

def task8_spam():
    values_train, values_test, labels_train, labels_test = split_dataset(spam_values, spam_labels)
    print("spam train proportions")
    print(proportions(labels_train))
    print("spam test proportions")
    print(proportions(labels_test))

#%%
task8_cancer()

#%%
task8_spam()

#%%
arr = np.array([1, 2, 3, 5])
mask = np.array([True, False, True, False])

print(arr[mask])
print(np.argmax([1, 2, 4, 3]))
#%%
# https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/
def gini(partition, labels):
    n_instances = labels.shape[0]
    size = np.sum(partition)
    if size == 0:
        return 0
    _, counts = np.unique(labels[partition], return_counts=True)
    score = np.sum(counts ** 2) / size ** 2
    return (1.0 - score) * (size / n_instances)
    
class Node:
    def __init__(self, depth):
        self.depth = depth
        self.value = None
        self.left = None
        self.right = None
        self.feature_index = None
        self.is_leaf = False
        self.labels = None
    
    def prob(self, mask, values, orig):
        actual_values = values[mask]
        if not np.any(mask):
            return None
        # simply count probs of each class in leaf by size 
        if self.is_leaf:
            classes_in_leaf, counts = np.unique(self.labels, return_counts=True)
            classes = np.unique(orig)
            positive_probabilities = np.array(counts[np.argsort(classes_in_leaf)] / np.sum(counts))
            
            # add zero prob
            pointer = 0
            all_probabilities = np.zeros(classes.shape[0])
            for i in range(classes.shape[0]):
                if pointer < classes_in_leaf.shape[0] and classes_in_leaf[pointer] == classes[i]:
                    all_probabilities[i] = positive_probabilities[pointer]
                    pointer += 1
                    
            return np.array([all_probabilities,]*np.sum(mask))
        
        right = actual_values[:, self.feature_index] >= self.value
        right_probabilities = self.right.prob(right, actual_values, orig)
        left = actual_values[:, self.feature_index] < self.value
        left_probabilities = self.left.prob(left, actual_values, orig)

        if left_probabilities is None:
            return right_probabilities
        elif right_probabilities is None:
            return left_probabilities
        else:
            all_probabilities = np.zeros((left_probabilities.shape[0] + right_probabilities.shape[0], left_probabilities.shape[1]))
            all_probabilities[left] = left_probabilities
            all_probabilities[right] = right_probabilities
            return all_probabilities
        
class DecisionTree:
    def __init__(self, max_depth):
        self.max_depth = max_depth

    def fit(self, values, labels):
        self.root = Node(depth=0)
        self.split(self.root, np.ones(values.shape[0], dtype=bool), values, labels)
    
    def split(self, node, mask, values, labels):
        actual_values = values[mask]
        actual_labels = labels[mask]
        
        if len(np.unique(actual_labels)) == 1 or node.depth == self.max_depth:
            node.labels = actual_labels
            node.is_leaf = True
            return
        
        ginis = []
        results = []
                
        for p_idx in range(actual_values.shape[0]):
            for f_idx in range(actual_values.shape[1]):
                features = actual_values[:, f_idx]
                pivot = features[p_idx]
                left = features < pivot
                right = features >= pivot
                ginis.append(gini(left, actual_labels) + gini(right, actual_labels))
                results.append((f_idx, pivot, left, right))
        
        
        node.feature_index, node.value, left, right = results[np.argmin(ginis)]
        
        node.left = Node(depth=node.depth + 1)
        node.right = Node(depth=node.depth + 1)
        self.split(node.left, left, actual_values, actual_labels)
        self.split(node.right, right, actual_values, actual_labels)
    
    def predict(self, values, labels):
        return np.argmax(self.prob(values, labels), axis=1)
        
    def prob(self, values, labels):
        return self.root.prob(np.ones(values.shape[0], dtype=bool), values, labels)

#%%
depths = range(1,11)
trees = [DecisionTree(max_depth=d) for d in depths]

#%%
# spam
from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt

def task9_spam():
    values_train, values_test, labels_train, labels_test = split_dataset(spam_values, spam_labels)
    print("spam")
    aucs = []
    for i, tree in enumerate(trees):
        tree.fit(values_train, labels_train)
        aucs.append(roc_auc_score(labels_test, tree.prob(values_test, labels_train)[:, 1]))
        print("depth = " + str(i) + "; AUC = " + str(aucs[i]))
        
    best_idx = np.argmax(np.array(aucs))
    print('best = ' + str(best_idx + 1) + ' with auc = ' + str(np.max(aucs)))
    
    best = trees[best_idx].prob(values_test, labels_test)
    plot_curve(roc_curve(labels_test, best[:, 1], pos_label=1))

task9_spam()

#%%
# cancer
from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt

def task9_cancer():
    values_train, values_test, labels_train, labels_test = split_dataset(cancer_values, cancer_labels)
    # pos_label='M' not working for me
    mapped_labels = list(map(lambda label: 1 if label == 'M' else 0, cancer_labels))
    mapped_labels_train = list(map(lambda label: 1 if label == 'M' else 0, labels_train))
    mapped_labels_test = list(map(lambda label: 1 if label == 'M' else 0, labels_test))
    print("cancer")
    aucs = []
    for i, tree in enumerate(trees):
        tree.fit(values_train, mapped_labels_train)
        aucs.append(roc_auc_score(mapped_labels_test, tree.prob(values_test, mapped_labels_train)[:, 1]))
        print("depth = " + str(i) + "; AUC = " + str(aucs[i]))
        
    best_idx = np.argmax(np.array(aucs))
    print('best = ' + str(best_idx + 1) + ' with auc = ' + str(np.max(aucs)))
    
    best = trees[best_idx].prob(values_test, mapped_labels_test)
    plot_curve(roc_curve(mapped_labels_test, best[:, 1], pos_label=1))

task9_cancer()